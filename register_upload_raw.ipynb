{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505ca1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\disha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Raw dataset uploaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, create_repo, upload_file\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "if HF_TOKEN is None:\n",
    "    raise ValueError(\"HF_TOKEN not found. Set it as an environment variable.\")\n",
    "\n",
    "username = \"Disha252001\"\n",
    "# Use a simple, valid repo name on Hugging Face (no spaces or parentheses)\n",
    "dataset_name = \"tourism-1\"\n",
    "repo_id = f\"{username}/{dataset_name}\"\n",
    "\n",
    "# Path to the actual CSV in your workspace\n",
    "local_file = \"master_folder/data/tourism (1).csv\"\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Create repo if it doesn't exist\n",
    "create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    token=HF_TOKEN,\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "# Upload raw CSV into /raw folder in HF dataset\n",
    "upload_file(\n",
    "    path_or_fileobj=local_file,\n",
    "    path_in_repo=\"raw/tourism (1).csv\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    token=HF_TOKEN,\n",
    "    commit_message=\"Upload raw tourism dataset\"\n",
    ")\n",
    "\n",
    "print(\"âœ” Raw dataset uploaded successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdbfacef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3302/3302 [00:00<00:00, 59901.01 examples/s]\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 826/826 [00:00<00:00, 71104.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201923</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200597</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>21062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204701</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>29654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204662</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>23647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202821</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>21221.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      201923          1  26.0  Company Invited         2             23.0   \n",
       "1      200597          0  42.0     Self Enquiry         1              6.0   \n",
       "2      204701          0  56.0  Company Invited         1              9.0   \n",
       "3      204662          1  27.0  Company Invited         3             36.0   \n",
       "4      202821          0  37.0     Self Enquiry         1              9.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       2                3.0   \n",
       "1        Salaried  Female                       2                4.0   \n",
       "2        Salaried    Male                       4                4.0   \n",
       "3  Small Business    Male                       4                6.0   \n",
       "4        Salaried  Female                       4                4.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0          Basic                    3.0       Married            1.0   \n",
       "1         Deluxe                    3.0      Divorced            1.0   \n",
       "2       Standard                    4.0       Married            5.0   \n",
       "3         Deluxe                    5.0     Unmarried            2.0   \n",
       "4          Basic                    3.0      Divorced            6.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       5       0                       1.0   \n",
       "1         1                       3       0                       1.0   \n",
       "2         0                       1       0                       2.0   \n",
       "3         0                       3       1                       2.0   \n",
       "4         0                       5       1                       1.0   \n",
       "\n",
       "      Designation  MonthlyIncome  \n",
       "0       Executive        17741.0  \n",
       "1         Manager        21062.0  \n",
       "2  Senior Manager        29654.0  \n",
       "3         Manager        23647.0  \n",
       "4       Executive        21221.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "repo_id = \"Disha252001/tourism-1\"\n",
    "\n",
    "dataset = load_dataset(repo_id)\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f89b77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201923</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200597</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>21062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204701</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>29654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204662</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>23647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202821</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>21221.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      201923          1  26.0  Company Invited         2             23.0   \n",
       "1      200597          0  42.0     Self Enquiry         1              6.0   \n",
       "2      204701          0  56.0  Company Invited         1              9.0   \n",
       "3      204662          1  27.0  Company Invited         3             36.0   \n",
       "4      202821          0  37.0     Self Enquiry         1              9.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       2                3.0   \n",
       "1        Salaried  Female                       2                4.0   \n",
       "2        Salaried    Male                       4                4.0   \n",
       "3  Small Business    Male                       4                6.0   \n",
       "4        Salaried  Female                       4                4.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0          Basic                    3.0       Married            1.0   \n",
       "1         Deluxe                    3.0      Divorced            1.0   \n",
       "2       Standard                    4.0       Married            5.0   \n",
       "3         Deluxe                    5.0     Unmarried            2.0   \n",
       "4          Basic                    3.0      Divorced            6.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       5       0                       1.0   \n",
       "1         1                       3       0                       1.0   \n",
       "2         0                       1       0                       2.0   \n",
       "3         0                       3       1                       2.0   \n",
       "4         0                       5       1                       1.0   \n",
       "\n",
       "      Designation  MonthlyIncome  \n",
       "0       Executive        17741.0  \n",
       "1         Manager        21062.0  \n",
       "2  Senior Manager        29654.0  \n",
       "3         Manager        23647.0  \n",
       "4       Executive        21221.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnamed index column if present\n",
    "df_clean = df.loc[:, ~df.columns.str.contains(\"Unnamed\")]\n",
    "\n",
    "# Drop any completely empty columns\n",
    "df_clean = df_clean.dropna(axis=1, how=\"all\")\n",
    "\n",
    "# Example: drop CustomerID if unnecessary\n",
    "# df_clean = df_clean.drop(columns=[\"CustomerID\"])\n",
    "\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39cbd307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test CSVs saved locally!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "print(\"Train and test CSVs saved locally!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e743a32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed train/test uploaded to HuggingFace!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import upload_file\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
    "repo_id = \"Disha252001/tourism-1\"\n",
    "\n",
    "# Upload train.csv\n",
    "upload_file(\n",
    "    path_or_fileobj=\"train.csv\",\n",
    "    path_in_repo=\"processed/train.csv\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "# Upload test.csv\n",
    "upload_file(\n",
    "    path_or_fileobj=\"test.csv\",\n",
    "    path_in_repo=\"processed/test.csv\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "print(\"Processed train/test uploaded to HuggingFace!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64595500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from huggingface_hub import upload_file\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Hugging Face credentials\n",
    "HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
    "repo_id = \"Disha252001/tourism-1\"\n",
    "\n",
    "# Load data\n",
    "dataset = load_dataset(repo_id, data_files={\"train\": \"processed/train.csv\", \"test\": \"processed/test.csv\"})\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Target column\n",
    "TARGET = \"ProdTaken\"\n",
    "DROP_COLS = [\"CustomerID\"]   # <-- IMPORTANT\n",
    "\n",
    "# Split features & target\n",
    "X_train = train_df.drop([TARGET] + DROP_COLS, axis=1)\n",
    "y_train = train_df[TARGET]\n",
    "\n",
    "X_test = test_df.drop([TARGET] + DROP_COLS, axis=1)\n",
    "y_test = test_df[TARGET]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ],\n",
    "    remainder='passthrough'  # numeric columns unchanged\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eca04c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models and hyperparameters\n",
    "models_params = {\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\"classifier__max_depth\": [None, 5, 10, 20],\n",
    "                   \"classifier__min_samples_split\": [2, 5, 10]}\n",
    "    },\n",
    "    \"Bagging\": {\n",
    "        \"model\": BaggingClassifier(random_state=42),\n",
    "        \"params\": {\"classifier__n_estimators\": [10, 50, 100],\n",
    "                   \"classifier__max_samples\": [0.5, 0.7, 1.0]}\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\"classifier__n_estimators\": [100, 200],\n",
    "                   \"classifier__max_depth\": [None, 10, 20],\n",
    "                   \"classifier__min_samples_split\": [2, 5]}\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"model\": AdaBoostClassifier(random_state=42),\n",
    "        \"params\": {\"classifier__n_estimators\": [50, 100, 200],\n",
    "                   \"classifier__learning_rate\": [0.01, 0.1, 1.0]}\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\"classifier__n_estimators\": [100, 200],\n",
    "                   \"classifier__learning_rate\": [0.01, 0.1, 0.2],\n",
    "                   \"classifier__max_depth\": [3, 5, 10]}\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\"),\n",
    "        \"params\": {\"classifier__n_estimators\": [100, 200],\n",
    "                   \"classifier__learning_rate\": [0.01, 0.1],\n",
    "                   \"classifier__max_depth\": [3, 5, 10]}\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56f58b0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "409 Client Error: Conflict for url: https://huggingface.co/api/repos/create (Request ID: Root=1-693aad43-63a26f8f38509e515fa3f30b;7dfad18e-7cbb-40d1-b588-e678b7b120c0)\n\nYou already created this model repo: Disha252001/tourism-1-models",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\disha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\disha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 409 Client Error: Conflict for url: https://huggingface.co/api/repos/create",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create a new model repo\u001b[39;00m\n\u001b[32m      4\u001b[39m model_repo_id = \u001b[33m\"\u001b[39m\u001b[33mDisha252001/tourism-1-models\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHF_TOKEN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel repo created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\disha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\disha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\hf_api.py:3511\u001b[39m, in \u001b[36mHfApi.create_repo\u001b[39m\u001b[34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[39m\n\u001b[32m   3508\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   3510\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3511\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3512\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   3513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err.response.status_code == \u001b[32m409\u001b[39m:\n\u001b[32m   3514\u001b[39m         \u001b[38;5;66;03m# Repo already exists and `exist_ok=True`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\disha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:481\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: 409 Client Error: Conflict for url: https://huggingface.co/api/repos/create (Request ID: Root=1-693aad43-63a26f8f38509e515fa3f30b;7dfad18e-7cbb-40d1-b588-e678b7b120c0)\n\nYou already created this model repo: Disha252001/tourism-1-models"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import create_repo\n",
    "\n",
    "# Create a new model repo\n",
    "model_repo_id = \"Disha252001/tourism-1-models\"\n",
    "create_repo(repo_id=model_repo_id, repo_type=\"model\", token=HF_TOKEN)\n",
    "print(f\"Model repo created: {model_repo_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "443cbf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training DecisionTree ===\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "DecisionTree Best Params: {'classifier__max_depth': None, 'classifier__min_samples_split': 2}\n",
      "DecisionTree Test Accuracy: 0.8729198184568835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       524\n",
      "           1       0.71      0.66      0.68       137\n",
      "\n",
      "    accuracy                           0.87       661\n",
      "   macro avg       0.81      0.80      0.80       661\n",
      "weighted avg       0.87      0.87      0.87       661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DecisionTree_best_model.joblib: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52.8k/52.8k [00:01<00:00, 34.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Bagging ===\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Bagging Best Params: {'classifier__max_samples': 1.0, 'classifier__n_estimators': 100}\n",
      "Bagging Test Accuracy: 0.8986384266263238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       524\n",
      "           1       0.86      0.61      0.71       137\n",
      "\n",
      "    accuracy                           0.90       661\n",
      "   macro avg       0.88      0.79      0.83       661\n",
      "weighted avg       0.90      0.90      0.89       661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bagging_best_model.joblib: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.70M/3.70M [00:05<00:00, 648kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training RandomForest ===\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "RandomForest Best Params: {'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
      "RandomForest Test Accuracy: 0.8910741301059002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93       524\n",
      "           1       0.90      0.53      0.67       137\n",
      "\n",
      "    accuracy                           0.89       661\n",
      "   macro avg       0.90      0.76      0.80       661\n",
      "weighted avg       0.89      0.89      0.88       661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest_best_model.joblib: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.50M/6.50M [00:11<00:00, 549kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training AdaBoost ===\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "AdaBoost Best Params: {'classifier__learning_rate': 1.0, 'classifier__n_estimators': 100}\n",
      "AdaBoost Test Accuracy: 0.8350983358547656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90       524\n",
      "           1       0.82      0.26      0.40       137\n",
      "\n",
      "    accuracy                           0.84       661\n",
      "   macro avg       0.83      0.62      0.65       661\n",
      "weighted avg       0.83      0.84      0.80       661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AdaBoost_best_model.joblib: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70.3k/70.3k [00:00<00:00, 205kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training GradientBoosting ===\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "GradientBoosting Best Params: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 10, 'classifier__n_estimators': 200}\n",
      "GradientBoosting Test Accuracy: 0.913767019667171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       524\n",
      "           1       0.90      0.66      0.76       137\n",
      "\n",
      "    accuracy                           0.91       661\n",
      "   macro avg       0.91      0.82      0.85       661\n",
      "weighted avg       0.91      0.91      0.91       661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GradientBoosting_best_model.joblib: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.78M/9.78M [00:27<00:00, 361kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training XGBoost ===\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\disha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:10:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Best Params: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 10, 'classifier__n_estimators': 200}\n",
      "XGBoost Test Accuracy: 0.8986384266263238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       524\n",
      "           1       0.84      0.63      0.72       137\n",
      "\n",
      "    accuracy                           0.90       661\n",
      "   macro avg       0.88      0.80      0.83       661\n",
      "weighted avg       0.90      0.90      0.89       661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost_best_model.joblib: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 956k/956k [00:02<00:00, 368kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† Best Model: GradientBoosting with accuracy 0.913767019667171\n"
     ]
    }
   ],
   "source": [
    "# Train models and upload to Hugging Face model repo\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "from huggingface_hub import upload_file\n",
    "\n",
    "# Update with your new model repo\n",
    "model_repo_id = \"Disha252001/tourism-1-models\"  # your newly created model repo\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for name, mp in models_params.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    \n",
    "    # Create pipeline with preprocessing\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', mp[\"model\"])])\n",
    "    \n",
    "    # Grid search for hyperparameter tuning\n",
    "    grid = GridSearchCV(pipeline, mp[\"params\"], cv=5, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{name} Best Params:\", grid.best_params_)\n",
    "    print(f\"{name} Test Accuracy:\", acc)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save locally\n",
    "    model_filename = f\"{name}_best_model.joblib\"\n",
    "    joblib.dump(best_model, model_filename)\n",
    "    \n",
    "    # Upload to Hugging Face model hub\n",
    "    upload_file(\n",
    "        path_or_fileobj=model_filename,\n",
    "        path_in_repo=f\"models/{model_filename}\",  # optional folder inside the repo\n",
    "        repo_id=model_repo_id,\n",
    "        repo_type=\"model\",\n",
    "        token=HF_TOKEN\n",
    "    )\n",
    "    \n",
    "    # Store best model info\n",
    "    best_models[name] = {\"model\": best_model, \"accuracy\": acc, \"params\": grid.best_params_}\n",
    "\n",
    "# Identify the overall best model\n",
    "best_model_name = max(best_models, key=lambda x: best_models[x][\"accuracy\"])\n",
    "print(f\"\\nðŸ† Best Model: {best_model_name} with accuracy {best_models[best_model_name]['accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96881b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"master_folder/deployment\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88a5f5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing master_folder/deployment/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile master_folder/deployment/Dockerfile\n",
    "# -------------------------\n",
    "#  Base Python Image\n",
    "# -------------------------\n",
    "FROM python:3.10-slim\n",
    "\n",
    "# -------------------------\n",
    "#  Setup Working Directory\n",
    "# -------------------------\n",
    "WORKDIR /app\n",
    "\n",
    "# -------------------------\n",
    "#  Copy Project Files\n",
    "# -------------------------\n",
    "COPY . /app\n",
    "\n",
    "# -------------------------\n",
    "#  Install Dependencies\n",
    "# -------------------------\n",
    "RUN pip install --no-cache-dir --upgrade pip\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# -------------------------\n",
    "#  Expose Streamlit Port\n",
    "# -------------------------\n",
    "EXPOSE 8501\n",
    "\n",
    "# -------------------------\n",
    "#  Run Streamlit App\n",
    "# -------------------------\n",
    "CMD [\"streamlit\", \"run\", \"app.py\", \\\n",
    "     \"--server.port=8501\", \\\n",
    "     \"--server.address=0.0.0.0\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45af8d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing master_folder/deployment/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile master_folder/deployment/requirements.txt\n",
    "streamlit\n",
    "huggingface_hub\n",
    "joblib\n",
    "pandas\n",
    "scikit-learn\n",
    "numpy\n",
    "xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "720cd38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting master_folder/deployment/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile master_folder/deployment/app.py\n",
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pathlib import Path\n",
    "\n",
    "st.set_page_config(page_title=\"Wellness Tourism Purchase Predictor\", layout=\"centered\")\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "# Model repo that you uploaded earlier (change if different)\n",
    "MODEL_REPO_ID = \"Disha252001/tourism-1-models\"   # <--- update if different\n",
    "MODEL_FILENAME = \"models/GradientBoosting_best_model.joblib\"  # change to whichever model file you uploaded\n",
    "\n",
    "# Hugging Face token (should be set in env for private models)\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", None)\n",
    "if HF_TOKEN is None:\n",
    "    st.warning(\"HF_TOKEN not found in environment â€” public models will still download, private ones will fail.\")\n",
    "\n",
    "# Local cache path for downloaded model\n",
    "cache_dir = Path.home() / \".cache\" / \"hf_models\"\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    try:\n",
    "        # Download model file from Hugging Face Hub to local cache\n",
    "        model_path = hf_hub_download(\n",
    "            repo_id=MODEL_REPO_ID,\n",
    "            filename=MODEL_FILENAME,\n",
    "            repo_type=\"model\",\n",
    "            token=HF_TOKEN,\n",
    "            cache_dir=str(cache_dir)\n",
    "        )\n",
    "        model = joblib.load(model_path)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        st.error(f\"Failed to load model from Hugging Face Hub: {e}\")\n",
    "        raise\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "st.title(\"Wellness Tourism â€” Purchase Prediction\")\n",
    "st.write(\"Fill the customer details below and click **Predict**.\")\n",
    "\n",
    "# --------------------------\n",
    "# Input form: fields based on your data dictionary\n",
    "# Fill or remove fields to match your training data exactly\n",
    "# --------------------------\n",
    "with st.form(\"input_form\"):\n",
    "\n",
    "    Age = st.number_input(\"Age\", min_value=0, max_value=120, value=35)\n",
    "    TypeofContact = st.selectbox(\"Type of Contact\", [\"Company Invited\", \"Self Inquiry\"])\n",
    "    CityTier = st.selectbox(\"City Tier\", [1, 2, 3], index=1)\n",
    "    Occupation = st.selectbox(\"Occupation\", [\"Salaried\", \"Freelancer\", \"Business\", \"Other\"])\n",
    "    Gender = st.selectbox(\"Gender\", [\"Male\", \"Female\"])\n",
    "    NumberOfPersonVisiting = st.number_input(\"Number Of Person Visiting\", min_value=0, value=2)\n",
    "    PreferredPropertyStar = st.number_input(\"Preferred Property Star\", min_value=1, max_value=7, value=5)\n",
    "    MaritalStatus = st.selectbox(\"Marital Status\", [\"Single\", \"Married\", \"Divorced\"])\n",
    "    NumberOfTrips = st.number_input(\"Number Of Trips (annual)\", min_value=0, value=2)\n",
    "    Passport = st.selectbox(\"Passport (0=No,1=Yes)\", [0,1], index=1)\n",
    "    OwnCar = st.selectbox(\"Own Car (0=No,1=Yes)\", [0,1], index=1)\n",
    "    NumberOfChildrenVisiting = st.number_input(\"Number Of Children Visiting (below 5)\", min_value=0, value=0)\n",
    "    Designation = st.text_input(\"Designation\", value=\"Manager\")\n",
    "    MonthlyIncome = st.number_input(\"Monthly Income\", min_value=0, value=50000)\n",
    "    PitchSatisfactionScore = st.number_input(\"Pitch Satisfaction Score (1-10)\", min_value=0, max_value=10, value=8)\n",
    "    ProductPitched = st.selectbox(\"Product Pitched\", [\"Wellness Package\", \"Family Package\", \"Other\"])\n",
    "    NumberOfFollowups = st.number_input(\"Number Of Followups\", min_value=0, value=1)\n",
    "    DurationOfPitch = st.number_input(\"Duration Of Pitch (minutes)\", min_value=0, value=10)\n",
    "\n",
    "    submitted = st.form_submit_button(\"Predict\")\n",
    "\n",
    "# --------------------------\n",
    "# Convert inputs to DataFrame and predict\n",
    "# --------------------------\n",
    "def build_input_df():\n",
    "    row = {\n",
    "        \"Age\": Age,\n",
    "        \"TypeofContact\": TypeofContact,\n",
    "        \"CityTier\": CityTier,\n",
    "        \"Occupation\": Occupation,\n",
    "        \"Gender\": Gender,\n",
    "        \"NumberOfPersonVisiting\": NumberOfPersonVisiting,\n",
    "        \"PreferredPropertyStar\": PreferredPropertyStar,\n",
    "        \"MaritalStatus\": MaritalStatus,\n",
    "        \"NumberOfTrips\": NumberOfTrips,\n",
    "        \"Passport\": Passport,\n",
    "        \"OwnCar\": OwnCar,\n",
    "        \"NumberOfChildrenVisiting\": NumberOfChildrenVisiting,\n",
    "        \"Designation\": Designation,\n",
    "        \"MonthlyIncome\": MonthlyIncome,\n",
    "        \"PitchSatisfactionScore\": PitchSatisfactionScore,\n",
    "        \"ProductPitched\": ProductPitched,\n",
    "        \"NumberOfFollowups\": NumberOfFollowups,\n",
    "        \"DurationOfPitch\": DurationOfPitch\n",
    "    }\n",
    "    df = pd.DataFrame([row])\n",
    "    return df\n",
    "\n",
    "if submitted:\n",
    "    input_df = build_input_df()\n",
    "    st.subheader(\"Input (as DataFrame)\")\n",
    "    st.dataframe(input_df)\n",
    "\n",
    "    # Model should be a pipeline with preprocessor so we can directly pass df\n",
    "    try:\n",
    "        pred = model.predict(input_df)\n",
    "        proba = None\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            proba = model.predict_proba(input_df)\n",
    "            # If binary, proba[:,1] is probability of class 1\n",
    "            if proba.shape[1] == 2:\n",
    "                proba = float(proba[:,1][0])\n",
    "            else:\n",
    "                # multi-class: show list\n",
    "                proba = [float(x) for x in proba[0]]\n",
    "        st.success(f\"Prediction (ProdTaken): {int(pred[0])}\")\n",
    "        if proba is not None:\n",
    "            st.info(f\"Probability: {proba}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Failed to predict: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c80aba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting master_folder/deployment/push_to_space.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile master_folder/deployment/push_to_space.py\n",
    "import os\n",
    "from huggingface_hub import create_repo, upload_file\n",
    "from pathlib import Path\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    raise RuntimeError(\"HF_TOKEN environment variable is required.\")\n",
    "\n",
    "SPACE_ID = \"Disha252001/wellness-tourism-space\"  \n",
    "LOCAL_DEPLOY_DIR = Path(__file__).resolve().parent  \n",
    "\n",
    "# 1) Create Space as DOCKER TYPE (correct)\n",
    "try:\n",
    "    create_repo(\n",
    "        repo_id=SPACE_ID,\n",
    "        token=HF_TOKEN,\n",
    "        repo_type=\"space\",\n",
    "        private=False,\n",
    "        space_sdk=\"docker\"      # <-- FIXED\n",
    "    )\n",
    "    print(f\"Space created: {SPACE_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"create_repo info (safe to ignore if exists): {e}\")\n",
    "\n",
    "# 2) Upload files\n",
    "files_to_upload = [\"Dockerfile\", \"requirements.txt\", \"app.py\", \".gitignore\"]\n",
    "\n",
    "for fname in files_to_upload:\n",
    "    local_path = LOCAL_DEPLOY_DIR / fname\n",
    "    if not local_path.exists():\n",
    "        print(f\"Skipping {fname} â€” not found.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Uploading {fname}...\")\n",
    "    upload_file(\n",
    "        path_or_fileobj=str(local_path),\n",
    "        path_in_repo=fname,\n",
    "        repo_id=SPACE_ID,\n",
    "        repo_type=\"space\",\n",
    "        token=HF_TOKEN\n",
    "    )\n",
    "\n",
    "print(f\"Done! Visit your Space:\")\n",
    "print(f\"https://huggingface.co/spaces/{SPACE_ID}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cfd2676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing master_folder/deployment/.gitignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile master_folder/deployment/.gitignore\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pkl\n",
    "*.joblib\n",
    ".env\n",
    "*.egg-info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e04622",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84eac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a710b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
